{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6V6/D/XR/CMeMCreD5INV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brainmentorspvtltd/IGDTU_ImageProcessingTF/blob/main/IG_FasterRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mBaZFblC9l2F"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mSS9hbDN9qrj",
        "outputId": "9a61c849-8c8e-4eb4-caaa-ca2f5fc34d0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 10000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "metadata": {
        "id": "0HwEOjuR-gG9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "RyXf3WQ0AgTd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = os.path.basename(repo_url)"
      ],
      "metadata": {
        "id": "0XeZFnGdAhJA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qyd8O4W4BKgJ",
        "outputId": "822525e5-a1b7-4085-cf61-e07ee9461af6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensorflow-object-detection-faster-rcnn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone {repo_url}\n",
        "%cd {root_dir}\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_0Yozho_REt",
        "outputId": "ea1a1185-ccce-48d5-b3c2-d023e30339b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 19.74 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H5GpI7i5_7_m",
        "outputId": "df987ad8-b2af-4bbd-eecd-f65a2e36e9d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensorflow-object-detection-faster-rcnn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SdDKMP3BW8X",
        "outputId": "af81b85a-5595-4a86-b9a7-565abbac13be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 123098 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package tk8.6-blt2.5.\n",
            "Preparing to unpack .../01-tk8.6-blt2.5_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package blt.\n",
            "Preparing to unpack .../02-blt_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking blt (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../03-libimagequant0_2.12.2-1.1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Selecting previously unselected package python-backports.functools-lru-cache.\n",
            "Preparing to unpack .../04-python-backports.functools-lru-cache_1.5-3build1_all.deb ...\n",
            "Unpacking python-backports.functools-lru-cache (1.5-3build1) ...\n",
            "Selecting previously unselected package python-soupsieve.\n",
            "Preparing to unpack .../05-python-soupsieve_1.9.5+dfsg-1_all.deb ...\n",
            "Unpacking python-soupsieve (1.9.5+dfsg-1) ...\n",
            "Selecting previously unselected package python-bs4.\n",
            "Preparing to unpack .../06-python-bs4_4.8.2-1_all.deb ...\n",
            "Unpacking python-bs4 (4.8.2-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../07-python-pkg-resources_44.0.0-2ubuntu0.1_all.deb ...\n",
            "Unpacking python-pkg-resources (44.0.0-2ubuntu0.1) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../08-python-chardet_3.0.4-4build1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-4build1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.14.0-2_all.deb ...\n",
            "Unpacking python-six (1.14.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../10-python-webencodings_0.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking python-webencodings (0.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../11-python-html5lib_1.0.1-2_all.deb ...\n",
            "Unpacking python-html5lib (1.0.1-2) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../12-python-lxml_4.5.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.5.0-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../13-python-olefile_0.46-2_all.deb ...\n",
            "Unpacking python-olefile (0.46-2) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../14-python-pil_6.2.1-3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (6.2.1-3) ...\n",
            "Selecting previously unselected package python-tk.\n",
            "Preparing to unpack .../15-python-tk_2.7.18-1_amd64.deb ...\n",
            "Unpacking python-tk (2.7.18-1) ...\n",
            "Setting up tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up blt (2.5.3+dfsg-4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up python-six (1.14.0-2) ...\n",
            "Setting up libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Setting up python-backports.functools-lru-cache (1.5-3build1) ...\n",
            "Setting up python-tk (2.7.18-1) ...\n",
            "Setting up python-webencodings (0.5.1-1ubuntu1) ...\n",
            "Setting up python-olefile (0.46-2) ...\n",
            "Setting up python-lxml:amd64 (4.5.0-1ubuntu0.5) ...\n",
            "Setting up python-html5lib (1.0.1-2) ...\n",
            "Setting up python-pkg-resources (44.0.0-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (6.2.1-3) ...\n",
            "Setting up python-soupsieve (1.9.5+dfsg-1) ...\n",
            "Setting up python-chardet (3.0.4-4build1) ...\n",
            "Setting up python-bs4 (4.8.2-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "/content/models/research\n",
            "2023-07-02 15:18:49.849828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_test.py\", line 20, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 37, in <module>\n",
            "    from object_detection.meta_architectures import deepmac_meta_arch\n",
            "  File \"/content/models/research/object_detection/meta_architectures/deepmac_meta_arch.py\", line 28, in <module>\n",
            "    import tensorflow_io as tfio  # pylint:disable=g-import-not-at-top\n",
            "ModuleNotFoundError: No module named 'tensorflow_io'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/models\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/models\")"
      ],
      "metadata": {
        "id": "SEg08DNqNYaD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Ovcob3Boza",
        "outputId": "8d9db2d8-5f29-4bf0-8bf0-05f223fa0e26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE THIS LINK - get our data from Roboflow\n",
        "!curl -L \"https://app.roboflow.com/ds/GlqM93wub9?key=x3YlyjrXsG\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_hQ1PKfCQU1",
        "outputId": "790e58ea-5b1c-4130-f5a5-8dd1790f2a6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   896  100   896    0     0   1839      0 --:--:-- --:--:-- --:--:--  1839\n",
            "100 3617k  100 3617k    0     0  1622k      0  0:00:02  0:00:02 --:--:-- 3972k\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/Workers.tfrecord   \n",
            " extracting: test/Workers_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/Workers.tfrecord  \n",
            " extracting: train/Workers_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/Workers.tfrecord  \n",
            " extracting: valid/Workers_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/{root_dir}"
      ],
      "metadata": {
        "id": "OFvZj9c-IPbQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %ls data/train\n",
        "\n",
        "%ls test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ju3d-rlIPWZ",
        "outputId": "9bb00de9-6da9-42e9-bc66-c1f525e196cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workers_label_map.pbtxt  Workers.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/valid/Workers.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/Wrokers.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/Workers_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "3PgmYLpKCTB5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h8bxlK7FcxM",
        "outputId": "00932969-ef44-4459-a6d0-188da45c1efc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJDJf0Z6Fg-S",
        "outputId": "015129ab-568b-426a-f493-b7f592efd7fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 23 root   root 4.0K Jul  2 15:20 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "guVvexr_F6Ar",
        "outputId": "81d40671-d57b-4f60-bfab-e4314f767511"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "metadata": {
        "id": "aHzg5xR2F9yh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "metadata": {
        "id": "vzP1tns2GAwo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "\n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "eOvp-fUsGCic"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {pipeline_fname}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScxAtd_mGFq_",
        "outputId": "e0450cd3-4783-418a-9294-a0b479ab18d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 3\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Wrokers.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Workers_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/valid/Workers.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Workers_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "kDNL9gsvMfeG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0niBa5dMk9F",
        "outputId": "468f272b-8d17-44aa-8a0b-8350e0c82d60"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-02 15:22:12--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.237.133.81, 54.161.241.46, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  5.99MB/s    in 2.2s    \n",
            "\n",
            "2023-07-02 15:22:15 (5.99 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "metadata": {
        "id": "mwti1bKMMnBB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "metadata": {
        "id": "TIszco0OMqBz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K6n-jV-MrrJ",
        "outputId": "b9c5690e-e265-43b7-d504-fff775fd13f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n",
            "    return loads(fp.read(),\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.10/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI4lFjA-Mtfh",
        "outputId": "844231f9-6453-4d5a-d190-1587ad79948e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.10/dist-packages (from lvis) (0.29.35)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (1.4.4)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from lvis) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from lvis) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis) (4.7.0.72)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lvis) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (4.40.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->lvis) (8.4.0)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8qLjGj6NE6r",
        "outputId": "1e85a438-d10b-4c76-8853-2f1d4f2237b1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.32.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iVZfvoFMyT7",
        "outputId": "0b66c7f6-f459-4d0b-a91a-45e47bd1f298"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-02 15:27:25.360245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0702 15:27:28.526270 140418465789760 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0702 15:27:28.615092 140418465789760 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0702 15:27:28.619843 140418465789760 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0702 15:27:28.620064 140418465789760 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 105, in main\n",
            "    model_lib_v2.train_loop(\n",
            "  File \"/content/models/research/object_detection/model_lib_v2.py\", line 531, in train_loop\n",
            "    raise ValueError('train_pb2.load_all_detection_checkpoint_vars '\n",
            "ValueError: train_pb2.load_all_detection_checkpoint_vars unsupported in TF2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJmoPlLWM1Eu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}